This Essay Explores the bias in the use of COMPAS in US Judicial System.

Governments have adopted machine algorithms and implemented them in criminal justice systems; courts are routinely using predictive models to aid judges to conduct more accurate and efficient trials. However, studies have shown that such algorithms are sometimes subjected to ethical implications such as racial bias and gender bias. 

In this paper, I am going to explain how predictive algorithm used in U.S. criminal justice system works and explore the ethical implications with one famous court case of Eric Loomis, where he was given an unfair sentence for his crime, as well as a research study conducted by Professor Hany from Dartmouth College. Finally, I will provide recommendations to mitigate and prevent unfairness in criminal justice system in all of individual, business, and government levels.
